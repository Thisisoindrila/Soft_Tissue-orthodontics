{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wwp8zDxdd42"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdduk1vceif4",
        "outputId": "8029c2f5-245d-4533-d813-2909bc5e885f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Concatenate, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Focal Loss definition\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())  # To prevent log(0)\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "        modulating_factor = K.pow(1. - y_pred, gamma)\n",
        "        loss = alpha * modulating_factor * cross_entropy\n",
        "        return K.sum(loss, axis=1)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "# Paths to CSV file and images folder\n",
        "csv_file = '/content/drive/MyDrive/Soft_Tissue/Final - Facial Profile Types.csv'\n",
        "image_folder = '/content/drive/MyDrive/Soft_Tissue/cepha400'\n",
        "\n",
        "# Step 2: Load the CSV file and preprocess\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Remove \"Concave - Convex\" class\n",
        "df = df[df['type'] != 'Concave - Convex']\n",
        "\n",
        "# Function to get zero-padded image filenames\n",
        "def get_image_path(image_id, folder):\n",
        "    image_filename = f\"{str(image_id).zfill(3)}.jpg\"  # Zero-pad the image ID\n",
        "    return os.path.join(folder, image_filename)\n",
        "\n",
        "# Link image paths with tabular data and labels\n",
        "images = []\n",
        "labels = []\n",
        "tabular_features = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    image_id = row['data']  # 'data' column\n",
        "    label = row['type']     # 'type' column\n",
        "    upper_lip = row['upper_lip']  # 'upper_lip' column\n",
        "    lower_lip = row['lower_lip']  # 'lower_lip' column\n",
        "\n",
        "    # Load image with zero-padded filename\n",
        "    image_path = get_image_path(image_id, image_folder)\n",
        "    try:\n",
        "        img = load_img(image_path, target_size=(224, 224))\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        images.append(img_array)\n",
        "        labels.append(label)\n",
        "        tabular_features.append([upper_lip, lower_lip])\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Image {image_path} not found.\")\n",
        "        continue\n",
        "\n",
        "# Convert images and tabular features to NumPy arrays\n",
        "images = np.array(images)\n",
        "tabular_features = np.array(tabular_features)\n",
        "\n",
        "# Encode tabular features using OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "tabular_features_encoded = encoder.fit_transform(tabular_features)\n",
        "\n",
        "# Encode the labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "labels_one_hot = to_categorical(labels_encoded)\n",
        "\n",
        "# Step 3: 5-Fold Cross Validation Setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 1\n",
        "for train_index, val_index in kf.split(images, labels_encoded):\n",
        "    print(f\"\\nTraining fold {fold_no}...\")\n",
        "\n",
        "    # Split the data\n",
        "    X_train_img, X_val_img = images[train_index], images[val_index]\n",
        "    X_train_tabular, X_val_tabular = tabular_features_encoded[train_index], tabular_features_encoded[val_index]\n",
        "    y_train, y_val = labels_one_hot[train_index], labels_one_hot[val_index]\n",
        "\n",
        "    # Step 4: Data augmentation for training set only\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=[0.8, 1.2],\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Augment training images\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "    augmented_tabular = []\n",
        "\n",
        "    for idx in range(len(X_train_img)):\n",
        "        img = X_train_img[idx]\n",
        "        label = y_train[idx]\n",
        "        tabular = X_train_tabular[idx]\n",
        "\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        for aug_img in datagen.flow(img, batch_size=1):\n",
        "            augmented_images.append(aug_img[0])\n",
        "            augmented_labels.append(label)\n",
        "            augmented_tabular.append(tabular)\n",
        "            if len(augmented_images) % 5 == 0:  # Generate 5 augmentations per image\n",
        "                break\n",
        "\n",
        "    # Combine original and augmented training data\n",
        "    X_train_img = np.vstack([X_train_img, np.array(augmented_images)])\n",
        "    y_train = np.vstack([y_train, np.array(augmented_labels)])\n",
        "    X_train_tabular = np.vstack([X_train_tabular, np.array(augmented_tabular)])\n",
        "\n",
        "    print(f\"New training set size for fold {fold_no}: {len(X_train_img)} images.\")\n",
        "\n",
        "    # Step 5: Build and compile a multimodal model\n",
        "    # Image model\n",
        "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in vgg16.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x_img = Flatten()(vgg16.output)\n",
        "\n",
        "    # Tabular model\n",
        "    input_tabular = Input(shape=(X_train_tabular.shape[1],), name=\"tabular_input\")\n",
        "    x_tabular = Dense(128, activation='relu')(input_tabular)\n",
        "\n",
        "    # Combine image and tabular features\n",
        "    combined = Concatenate()([x_img, x_tabular])\n",
        "    x = Dense(256, activation='relu')(combined)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(y_train.shape[1], activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[vgg16.input, input_tabular], outputs=output)\n",
        "\n",
        "    # ASMGrad in Adam optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, amsgrad=True)\n",
        "\n",
        "    # Compile the model with Focal Loss and ASMGrad optimizer\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=focal_loss(gamma=2., alpha=0.25),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Step 6: Train the model for the current fold\n",
        "    history = model.fit(\n",
        "        [X_train_img, X_train_tabular], y_train,\n",
        "        validation_data=([X_val_img, X_val_tabular], y_val),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Step 7: Evaluate the model and calculate F1 Score for the current fold\n",
        "    val_loss, val_accuracy = model.evaluate([X_val_img, X_val_tabular], y_val, verbose=0)\n",
        "    print(f\"Validation Loss for fold {fold_no}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy for fold {fold_no}: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = model.predict([X_val_img, X_val_tabular])\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_val, axis=1)\n",
        "\n",
        "    # Classification Report for the fold\n",
        "    print(\"\\nClassification Report for fold {fold_no}:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
        "\n",
        "    # Calculate F1 Scores for the fold\n",
        "    macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
        "    weighted_f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    print(f\"\\nMacro-Average F1 Score for fold {fold_no}: {macro_f1:.4f}\")\n",
        "    print(f\"Weighted-Average F1 Score for fold {fold_no}: {weighted_f1:.4f}\")\n",
        "\n",
        "    fold_no += 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBNBZoi1f3Be",
        "outputId": "e16cfa21-d762-4619-ecce-f976d73a8188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training fold 1...\n",
            "New training set size for fold 1: 1914 images.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 508ms/step - accuracy: 0.4337 - loss: 0.5452 - val_accuracy: 0.6125 - val_loss: 0.1280\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - accuracy: 0.6162 - loss: 0.1369 - val_accuracy: 0.6250 - val_loss: 0.1254\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.6583 - loss: 0.1138 - val_accuracy: 0.7500 - val_loss: 0.0819\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7881 - loss: 0.0763 - val_accuracy: 0.9125 - val_loss: 0.0523\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - accuracy: 0.8657 - loss: 0.0460 - val_accuracy: 0.8875 - val_loss: 0.0396\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.8929 - loss: 0.0332 - val_accuracy: 0.9500 - val_loss: 0.0243\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 0.9156 - loss: 0.0260 - val_accuracy: 0.9750 - val_loss: 0.0160\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9420 - loss: 0.0177 - val_accuracy: 0.9625 - val_loss: 0.0142\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9532 - loss: 0.0150 - val_accuracy: 0.9875 - val_loss: 0.0095\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9620 - loss: 0.0126 - val_accuracy: 0.9750 - val_loss: 0.0079\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.9722 - loss: 0.0099 - val_accuracy: 0.9750 - val_loss: 0.0072\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.9657 - loss: 0.0093 - val_accuracy: 0.9875 - val_loss: 0.0066\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9749 - loss: 0.0083 - val_accuracy: 0.9875 - val_loss: 0.0045\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9759 - loss: 0.0072 - val_accuracy: 0.9750 - val_loss: 0.0044\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9697 - loss: 0.0069 - val_accuracy: 0.9875 - val_loss: 0.0029\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9770 - loss: 0.0067 - val_accuracy: 0.9875 - val_loss: 0.0045\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9780 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9873 - loss: 0.0050 - val_accuracy: 0.9875 - val_loss: 0.0030\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9746 - loss: 0.0061 - val_accuracy: 0.9875 - val_loss: 0.0021\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.9816 - loss: 0.0044 - val_accuracy: 0.9875 - val_loss: 0.0018\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.9678 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9767 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 6.8077e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9831 - loss: 0.0043 - val_accuracy: 0.9875 - val_loss: 0.0022\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.9744 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 4.6613e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.9854 - loss: 0.0040 - val_accuracy: 0.9875 - val_loss: 0.0020\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9807 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9786 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 9.1722e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.9829 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9871 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 8.9982e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9862 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 9.7540e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9767 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9786 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 4.1696e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9908 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.9870 - loss: 0.0031 - val_accuracy: 0.9875 - val_loss: 0.0018\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.9866 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 4.7376e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9855 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 4.4107e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9797 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9801 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 3.6791e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9773 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 3.7144e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9885 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 2.8152e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9840 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 3.4518e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9847 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 2.9442e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9863 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.6507e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9863 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 3.2728e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.9796 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 4.1817e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9848 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 6.9383e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9849 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 2.0974e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9908 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 5.5153e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.9875 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 3.3598e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9841 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 3.6789e-04\n",
            "Validation Loss for fold 1: 0.0004\n",
            "Validation Accuracy for fold 1: 1.0000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step\n",
            "\n",
            "Classification Report for fold {fold_no}:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Concave       1.00      1.00      1.00        49\n",
            "          Convex       1.00      1.00      1.00        14\n",
            "Convex - Concave       1.00      1.00      1.00         4\n",
            "           Plane       1.00      1.00      1.00        13\n",
            "\n",
            "        accuracy                           1.00        80\n",
            "       macro avg       1.00      1.00      1.00        80\n",
            "    weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "\n",
            "Macro-Average F1 Score for fold 1: 1.0000\n",
            "Weighted-Average F1 Score for fold 1: 1.0000\n",
            "\n",
            "Training fold 2...\n",
            "New training set size for fold 2: 1914 images.\n",
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 184ms/step - accuracy: 0.4658 - loss: 0.5230 - val_accuracy: 0.6000 - val_loss: 0.1263\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 130ms/step - accuracy: 0.5907 - loss: 0.1312 - val_accuracy: 0.6000 - val_loss: 0.1238\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.5974 - loss: 0.1207 - val_accuracy: 0.6375 - val_loss: 0.0968\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.6647 - loss: 0.0946 - val_accuracy: 0.7625 - val_loss: 0.0769\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.6985 - loss: 0.0796 - val_accuracy: 0.7625 - val_loss: 0.0663\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.7618 - loss: 0.0660 - val_accuracy: 0.9250 - val_loss: 0.0500\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.7654 - loss: 0.0630 - val_accuracy: 0.9375 - val_loss: 0.0434\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.7973 - loss: 0.0516 - val_accuracy: 0.9375 - val_loss: 0.0345\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.7969 - loss: 0.0526 - val_accuracy: 0.9375 - val_loss: 0.0368\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8177 - loss: 0.0484 - val_accuracy: 0.9375 - val_loss: 0.0291\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 0.8210 - loss: 0.0435 - val_accuracy: 0.9375 - val_loss: 0.0283\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8317 - loss: 0.0430 - val_accuracy: 0.9375 - val_loss: 0.0234\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8319 - loss: 0.0407 - val_accuracy: 0.9375 - val_loss: 0.0236\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8281 - loss: 0.0404 - val_accuracy: 0.9375 - val_loss: 0.0221\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8276 - loss: 0.0386 - val_accuracy: 0.9375 - val_loss: 0.0237\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8476 - loss: 0.0401 - val_accuracy: 0.9625 - val_loss: 0.0183\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.8766 - loss: 0.0369 - val_accuracy: 0.9500 - val_loss: 0.0168\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8790 - loss: 0.0354 - val_accuracy: 0.9750 - val_loss: 0.0163\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8706 - loss: 0.0344 - val_accuracy: 0.9500 - val_loss: 0.0174\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9025 - loss: 0.0315 - val_accuracy: 0.9625 - val_loss: 0.0154\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8934 - loss: 0.0332 - val_accuracy: 0.9750 - val_loss: 0.0153\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8897 - loss: 0.0324 - val_accuracy: 0.9625 - val_loss: 0.0141\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8737 - loss: 0.0363 - val_accuracy: 0.9750 - val_loss: 0.0144\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8708 - loss: 0.0346 - val_accuracy: 0.9750 - val_loss: 0.0136\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8871 - loss: 0.0302 - val_accuracy: 0.9750 - val_loss: 0.0129\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8978 - loss: 0.0313 - val_accuracy: 0.9750 - val_loss: 0.0143\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8809 - loss: 0.0351 - val_accuracy: 0.9750 - val_loss: 0.0145\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8884 - loss: 0.0323 - val_accuracy: 0.9750 - val_loss: 0.0140\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.8877 - loss: 0.0295 - val_accuracy: 0.9625 - val_loss: 0.0143\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.8871 - loss: 0.0307 - val_accuracy: 0.9750 - val_loss: 0.0121\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8792 - loss: 0.0324 - val_accuracy: 0.9500 - val_loss: 0.0156\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.9006 - loss: 0.0283 - val_accuracy: 0.9750 - val_loss: 0.0127\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8768 - loss: 0.0323 - val_accuracy: 0.9750 - val_loss: 0.0128\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8898 - loss: 0.0301 - val_accuracy: 0.9500 - val_loss: 0.0145\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8731 - loss: 0.0346 - val_accuracy: 0.9875 - val_loss: 0.0120\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8890 - loss: 0.0287 - val_accuracy: 0.9750 - val_loss: 0.0131\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - accuracy: 0.8819 - loss: 0.0327 - val_accuracy: 0.9750 - val_loss: 0.0137\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8906 - loss: 0.0292 - val_accuracy: 0.9625 - val_loss: 0.0136\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8930 - loss: 0.0286 - val_accuracy: 0.9625 - val_loss: 0.0137\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8898 - loss: 0.0278 - val_accuracy: 0.9875 - val_loss: 0.0139\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8769 - loss: 0.0323 - val_accuracy: 0.9750 - val_loss: 0.0124\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.8923 - loss: 0.0307 - val_accuracy: 0.9875 - val_loss: 0.0130\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.8985 - loss: 0.0238 - val_accuracy: 0.9750 - val_loss: 0.0136\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8974 - loss: 0.0267 - val_accuracy: 0.9750 - val_loss: 0.0138\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8891 - loss: 0.0295 - val_accuracy: 0.9750 - val_loss: 0.0122\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8979 - loss: 0.0288 - val_accuracy: 0.9750 - val_loss: 0.0121\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8971 - loss: 0.0291 - val_accuracy: 0.9750 - val_loss: 0.0131\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.8849 - loss: 0.0294 - val_accuracy: 0.9750 - val_loss: 0.0127\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.8995 - loss: 0.0259 - val_accuracy: 0.9875 - val_loss: 0.0132\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8868 - loss: 0.0299 - val_accuracy: 0.9625 - val_loss: 0.0131\n",
            "Validation Loss for fold 2: 0.0131\n",
            "Validation Accuracy for fold 2: 0.9625\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step\n",
            "\n",
            "Classification Report for fold {fold_no}:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Concave       0.96      1.00      0.98        48\n",
            "          Convex       1.00      0.93      0.97        15\n",
            "Convex - Concave       1.00      0.50      0.67         4\n",
            "           Plane       0.93      1.00      0.96        13\n",
            "\n",
            "        accuracy                           0.96        80\n",
            "       macro avg       0.97      0.86      0.89        80\n",
            "    weighted avg       0.96      0.96      0.96        80\n",
            "\n",
            "\n",
            "Macro-Average F1 Score for fold 2: 0.8937\n",
            "Weighted-Average F1 Score for fold 2: 0.9586\n",
            "\n",
            "Training fold 3...\n",
            "New training set size for fold 3: 1914 images.\n",
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 185ms/step - accuracy: 0.4856 - loss: 0.5994 - val_accuracy: 0.6000 - val_loss: 0.1329\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.5936 - loss: 0.1382 - val_accuracy: 0.6000 - val_loss: 0.1178\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.6208 - loss: 0.1247 - val_accuracy: 0.6000 - val_loss: 0.1043\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.6182 - loss: 0.1039 - val_accuracy: 0.7625 - val_loss: 0.0859\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - accuracy: 0.7122 - loss: 0.0822 - val_accuracy: 0.7750 - val_loss: 0.0669\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.7498 - loss: 0.0672 - val_accuracy: 0.7750 - val_loss: 0.0480\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.7871 - loss: 0.0546 - val_accuracy: 0.7750 - val_loss: 0.0388\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.7781 - loss: 0.0499 - val_accuracy: 0.8125 - val_loss: 0.0337\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.8067 - loss: 0.0440 - val_accuracy: 0.8750 - val_loss: 0.0280\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8157 - loss: 0.0425 - val_accuracy: 0.8750 - val_loss: 0.0288\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.8505 - loss: 0.0347 - val_accuracy: 0.8625 - val_loss: 0.0231\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8449 - loss: 0.0357 - val_accuracy: 0.9375 - val_loss: 0.0222\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.8597 - loss: 0.0360 - val_accuracy: 0.9000 - val_loss: 0.0208\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8668 - loss: 0.0303 - val_accuracy: 0.9375 - val_loss: 0.0204\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8624 - loss: 0.0322 - val_accuracy: 0.9625 - val_loss: 0.0188\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.8746 - loss: 0.0303 - val_accuracy: 0.9500 - val_loss: 0.0187\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8580 - loss: 0.0301 - val_accuracy: 0.9250 - val_loss: 0.0164\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8711 - loss: 0.0296 - val_accuracy: 0.9625 - val_loss: 0.0149\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8776 - loss: 0.0266 - val_accuracy: 0.9625 - val_loss: 0.0157\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8559 - loss: 0.0294 - val_accuracy: 0.9250 - val_loss: 0.0149\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.8711 - loss: 0.0277 - val_accuracy: 0.9750 - val_loss: 0.0116\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.8802 - loss: 0.0258 - val_accuracy: 0.9750 - val_loss: 0.0105\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8857 - loss: 0.0249 - val_accuracy: 0.9750 - val_loss: 0.0114\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8977 - loss: 0.0235 - val_accuracy: 0.9750 - val_loss: 0.0098\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8973 - loss: 0.0245 - val_accuracy: 0.9750 - val_loss: 0.0110\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8991 - loss: 0.0214 - val_accuracy: 0.9750 - val_loss: 0.0064\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8873 - loss: 0.0223 - val_accuracy: 0.9875 - val_loss: 0.0079\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.9133 - loss: 0.0198 - val_accuracy: 0.9875 - val_loss: 0.0063\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - accuracy: 0.9041 - loss: 0.0227 - val_accuracy: 0.9875 - val_loss: 0.0049\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9155 - loss: 0.0186 - val_accuracy: 0.9875 - val_loss: 0.0083\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9226 - loss: 0.0169 - val_accuracy: 0.9875 - val_loss: 0.0048\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9203 - loss: 0.0188 - val_accuracy: 0.9875 - val_loss: 0.0065\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9129 - loss: 0.0193 - val_accuracy: 0.9875 - val_loss: 0.0049\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9214 - loss: 0.0186 - val_accuracy: 0.9875 - val_loss: 0.0048\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9157 - loss: 0.0181 - val_accuracy: 0.9875 - val_loss: 0.0055\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.9262 - loss: 0.0162 - val_accuracy: 0.9875 - val_loss: 0.0038\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9177 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9080 - loss: 0.0193 - val_accuracy: 0.9875 - val_loss: 0.0041\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9116 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.9243 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9132 - loss: 0.0179 - val_accuracy: 0.9875 - val_loss: 0.0021\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.9075 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.9247 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9250 - loss: 0.0170 - val_accuracy: 0.9875 - val_loss: 0.0020\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.9118 - loss: 0.0187 - val_accuracy: 0.9875 - val_loss: 0.0035\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9206 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9185 - loss: 0.0167 - val_accuracy: 0.9875 - val_loss: 0.0021\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9050 - loss: 0.0196 - val_accuracy: 0.9875 - val_loss: 0.0048\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.9048 - loss: 0.0185 - val_accuracy: 0.9875 - val_loss: 0.0029\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.9081 - loss: 0.0182 - val_accuracy: 0.9875 - val_loss: 0.0031\n",
            "Validation Loss for fold 3: 0.0031\n",
            "Validation Accuracy for fold 3: 0.9875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c4eaff26e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c4eaff26e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step\n",
            "\n",
            "Classification Report for fold {fold_no}:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Concave       1.00      1.00      1.00        48\n",
            "          Convex       1.00      0.93      0.97        15\n",
            "Convex - Concave       1.00      1.00      1.00         4\n",
            "           Plane       0.93      1.00      0.96        13\n",
            "\n",
            "        accuracy                           0.99        80\n",
            "       macro avg       0.98      0.98      0.98        80\n",
            "    weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "\n",
            "Macro-Average F1 Score for fold 3: 0.9821\n",
            "Weighted-Average F1 Score for fold 3: 0.9875\n",
            "\n",
            "Training fold 4...\n",
            "New training set size for fold 4: 1914 images.\n",
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 181ms/step - accuracy: 0.4731 - loss: 0.4379 - val_accuracy: 0.6000 - val_loss: 0.1369\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.5731 - loss: 0.1475 - val_accuracy: 0.6000 - val_loss: 0.1209\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.5953 - loss: 0.1183 - val_accuracy: 0.6000 - val_loss: 0.1029\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.6852 - loss: 0.0948 - val_accuracy: 0.7875 - val_loss: 0.0701\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - accuracy: 0.8286 - loss: 0.0583 - val_accuracy: 0.9375 - val_loss: 0.0424\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8568 - loss: 0.0423 - val_accuracy: 0.9375 - val_loss: 0.0397\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8387 - loss: 0.0412 - val_accuracy: 0.9625 - val_loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.8949 - loss: 0.0270 - val_accuracy: 0.9875 - val_loss: 0.0146\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9110 - loss: 0.0223 - val_accuracy: 0.9625 - val_loss: 0.0117\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.8862 - loss: 0.0238 - val_accuracy: 0.9625 - val_loss: 0.0087\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.9171 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9260 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9174 - loss: 0.0166 - val_accuracy: 0.9875 - val_loss: 0.0052\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9224 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9248 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9304 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.9249 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9338 - loss: 0.0125 - val_accuracy: 0.9750 - val_loss: 0.0060\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9237 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.9377 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9290 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9447 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9330 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 9.9779e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9517 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9381 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 7.6041e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.9298 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 6.4706e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9442 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9456 - loss: 0.0089 - val_accuracy: 0.9875 - val_loss: 0.0016\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9461 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 4.3313e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9431 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 7.2132e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9244 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 6.3945e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9464 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 2.0685e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.9408 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 6.9917e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9333 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 5.5556e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.9401 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 3.3792e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9468 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 4.8523e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9385 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 1.6498e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9456 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 3.4255e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9490 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 5.1461e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9371 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 2.6566e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9517 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 7.7183e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9466 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 2.5855e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.9426 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.9300 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 3.0354e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.9467 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 9.4877e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.9361 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.9241 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 4.6989e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.9473 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 2.3786e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9490 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 6.7095e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9445 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 5.1624e-04\n",
            "Validation Loss for fold 4: 0.0005\n",
            "Validation Accuracy for fold 4: 1.0000\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step\n",
            "\n",
            "Classification Report for fold {fold_no}:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Concave       1.00      1.00      1.00        48\n",
            "          Convex       1.00      1.00      1.00        15\n",
            "Convex - Concave       1.00      1.00      1.00         4\n",
            "           Plane       1.00      1.00      1.00        13\n",
            "\n",
            "        accuracy                           1.00        80\n",
            "       macro avg       1.00      1.00      1.00        80\n",
            "    weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "\n",
            "Macro-Average F1 Score for fold 4: 1.0000\n",
            "Weighted-Average F1 Score for fold 4: 1.0000\n",
            "\n",
            "Training fold 5...\n",
            "New training set size for fold 5: 1920 images.\n",
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.4465 - loss: 0.4036 - val_accuracy: 0.6076 - val_loss: 0.1245\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - accuracy: 0.5732 - loss: 0.1356 - val_accuracy: 0.6076 - val_loss: 0.1141\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.6015 - loss: 0.1228 - val_accuracy: 0.6076 - val_loss: 0.0924\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.6738 - loss: 0.0938 - val_accuracy: 0.7595 - val_loss: 0.0715\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.7123 - loss: 0.0754 - val_accuracy: 0.7595 - val_loss: 0.0574\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.7393 - loss: 0.0626 - val_accuracy: 0.8481 - val_loss: 0.0473\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.7852 - loss: 0.0569 - val_accuracy: 0.8481 - val_loss: 0.0446\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7909 - loss: 0.0508 - val_accuracy: 0.9241 - val_loss: 0.0372\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8005 - loss: 0.0497 - val_accuracy: 0.9241 - val_loss: 0.0335\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8477 - loss: 0.0411 - val_accuracy: 0.9494 - val_loss: 0.0299\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8709 - loss: 0.0381 - val_accuracy: 0.9494 - val_loss: 0.0246\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.8433 - loss: 0.0364 - val_accuracy: 0.9494 - val_loss: 0.0230\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8602 - loss: 0.0338 - val_accuracy: 0.9494 - val_loss: 0.0205\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8565 - loss: 0.0329 - val_accuracy: 0.9494 - val_loss: 0.0200\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8532 - loss: 0.0344 - val_accuracy: 0.9494 - val_loss: 0.0215\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8567 - loss: 0.0338 - val_accuracy: 0.9494 - val_loss: 0.0209\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8616 - loss: 0.0326 - val_accuracy: 0.9494 - val_loss: 0.0192\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8470 - loss: 0.0334 - val_accuracy: 0.9494 - val_loss: 0.0187\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8698 - loss: 0.0288 - val_accuracy: 0.9494 - val_loss: 0.0162\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8471 - loss: 0.0342 - val_accuracy: 0.9494 - val_loss: 0.0153\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8729 - loss: 0.0298 - val_accuracy: 0.9747 - val_loss: 0.0151\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8640 - loss: 0.0298 - val_accuracy: 0.9620 - val_loss: 0.0157\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8605 - loss: 0.0302 - val_accuracy: 0.9747 - val_loss: 0.0135\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8720 - loss: 0.0280 - val_accuracy: 0.9620 - val_loss: 0.0148\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8755 - loss: 0.0288 - val_accuracy: 0.9620 - val_loss: 0.0135\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.8735 - loss: 0.0289 - val_accuracy: 0.9747 - val_loss: 0.0146\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8649 - loss: 0.0307 - val_accuracy: 0.9747 - val_loss: 0.0133\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.8545 - loss: 0.0308 - val_accuracy: 0.9620 - val_loss: 0.0131\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8609 - loss: 0.0323 - val_accuracy: 0.9747 - val_loss: 0.0129\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8762 - loss: 0.0290 - val_accuracy: 0.9620 - val_loss: 0.0140\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.8517 - loss: 0.0308 - val_accuracy: 0.9747 - val_loss: 0.0128\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8636 - loss: 0.0298 - val_accuracy: 0.9620 - val_loss: 0.0154\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.8658 - loss: 0.0297 - val_accuracy: 0.9620 - val_loss: 0.0136\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8600 - loss: 0.0310 - val_accuracy: 0.9620 - val_loss: 0.0168\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8816 - loss: 0.0288 - val_accuracy: 0.9620 - val_loss: 0.0152\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.8669 - loss: 0.0292 - val_accuracy: 0.9620 - val_loss: 0.0166\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8499 - loss: 0.0327 - val_accuracy: 0.9873 - val_loss: 0.0105\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8769 - loss: 0.0286 - val_accuracy: 0.9747 - val_loss: 0.0117\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8709 - loss: 0.0294 - val_accuracy: 0.9620 - val_loss: 0.0135\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8741 - loss: 0.0299 - val_accuracy: 0.9747 - val_loss: 0.0118\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.8621 - loss: 0.0291 - val_accuracy: 0.9747 - val_loss: 0.0133\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8678 - loss: 0.0273 - val_accuracy: 0.9620 - val_loss: 0.0139\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8574 - loss: 0.0295 - val_accuracy: 0.9620 - val_loss: 0.0154\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.8785 - loss: 0.0267 - val_accuracy: 0.9620 - val_loss: 0.0112\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.8579 - loss: 0.0303 - val_accuracy: 0.9620 - val_loss: 0.0140\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.8721 - loss: 0.0292 - val_accuracy: 0.9620 - val_loss: 0.0136\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8587 - loss: 0.0303 - val_accuracy: 0.9620 - val_loss: 0.0154\n",
            "Epoch 48/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.8675 - loss: 0.0278 - val_accuracy: 0.9620 - val_loss: 0.0124\n",
            "Epoch 49/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.8689 - loss: 0.0292 - val_accuracy: 0.9620 - val_loss: 0.0117\n",
            "Epoch 50/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8566 - loss: 0.0280 - val_accuracy: 0.9620 - val_loss: 0.0114\n",
            "Validation Loss for fold 5: 0.0114\n",
            "Validation Accuracy for fold 5: 0.9620\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step\n",
            "\n",
            "Classification Report for fold {fold_no}:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Concave       1.00      1.00      1.00        48\n",
            "          Convex       0.83      1.00      0.91        15\n",
            "Convex - Concave       1.00      0.25      0.40         4\n",
            "           Plane       1.00      1.00      1.00        12\n",
            "\n",
            "        accuracy                           0.96        79\n",
            "       macro avg       0.96      0.81      0.83        79\n",
            "    weighted avg       0.97      0.96      0.95        79\n",
            "\n",
            "\n",
            "Macro-Average F1 Score for fold 5: 0.8273\n",
            "Weighted-Average F1 Score for fold 5: 0.9524\n"
          ]
        }
      ]
    }
  ]
}